{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f60668b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from utils.model_loader import ModelLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c85d187e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2025-08-25T16:20:25.579838Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-08-25T16:20:25.583094Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2025-08-25T16:20:25.586522Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_eh...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-08-25T16:20:25.592517Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"faiss_db\", \"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-08-25T16:20:25.602825Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n"
     ]
    }
   ],
   "source": [
    "loader = ModelLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e56e037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-08-25T16:20:26.595381Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Loaded: model='models/gemini-2.0-flash' google_api_key=SecretStr('**********') temperature=0.0 max_output_tokens=2048 client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000204C8571930> default_metadata=() model_kwargs={}\n",
      "LLM Result: I am doing well, thank you for asking! As a large language model, I don't experience emotions or feelings like humans do, but I am functioning optimally and ready to assist you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "llm = loader.load_llm()\n",
    "print(f\"LLM Loaded: {llm}\")\n",
    "result = llm.invoke(\"Hello, how are you?\")\n",
    "print(f\"LLM Result: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f6e8f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24957cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45bf9e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"Give me a JSON with keys 'title' and 'summary' for this topic: {topic}\\n{format_instructions}\"\n",
    ").partial(format_instructions=parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebdad479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={'format_instructions': 'Return a JSON object.'}, template=\"Give me a JSON with keys 'title' and 'summary' for this topic: {topic}\\n{format_instructions}\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33cd1fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd7f6189",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"topic\": \"LangChain for RAG\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a06a59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'LangChain for Retrieval Augmented Generation (RAG)',\n",
       " 'summary': 'LangChain simplifies the development of Retrieval Augmented Generation (RAG) applications. It provides modules for connecting to data sources, creating embeddings, indexing data, and orchestrating the retrieval and generation process. By leveraging LangChain, developers can build powerful RAG systems that combine the strengths of large language models with external knowledge to improve accuracy, reduce hallucinations, and provide more contextually relevant responses.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4769691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import OutputFixingParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d297cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_parser = JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a4da03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing wrapper\n",
    "fixing_parser = OutputFixingParser.from_llm(parser=json_parser, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2713a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broken JSON\n",
    "bad_output = \"\"\"\n",
    "title: LangChain RAG\n",
    "summary LangChain helps with retrieval augmented generation...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "476c522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_result = fixing_parser.parse(bad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22d55997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'LangChain RAG', 'summary': 'LangChain helps with retrieval augmented generation...'}\n"
     ]
    }
   ],
   "source": [
    "print(fixed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2a1cd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.output_parsers import OutputFixingParser\n",
    "# from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# json_parser = JsonOutputParser()\n",
    "# safe_parser = OutputFixingParser.from_llm(parser=json_parser, llm=llm)\n",
    "\n",
    "# # Use safe_parser instead of json_parser\n",
    "# chain = prompt | llm | safe_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0e7693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap with cache\n",
    "Model_Cache = {}\n",
    "\n",
    "import time\n",
    "def cached_model(query):\n",
    "    start_time = time.time()\n",
    "    if Model_Cache.get(query):\n",
    "        print(\"***CACHE HIT***\")\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(f\"EXECUTION TIME: {elapsed:.2f} seconds\")\n",
    "        return Model_Cache.get(query)\n",
    "    else:\n",
    "        print(\"***CACHE MISS – EXECUTING MODEL***\")\n",
    "        start_time = time.time()\n",
    "        response = llm.invoke(query)\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(f\"EXECUTION TIME: {elapsed:.2f} seconds\")\n",
    "        Model_Cache[query] = response\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa3d0c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CACHE MISS – EXECUTING MODEL***\n",
      "EXECUTION TIME: 0.85 seconds\n",
      "content='Hi there! How can I help you today?' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--1d98af07-711d-4d11-a5d7-8802a32efeaa-0' usage_metadata={'input_tokens': 1, 'output_tokens': 11, 'total_tokens': 12, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "query=\"hi\"\n",
    "response = cached_model(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "737a7aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CACHE MISS – EXECUTING MODEL***\n",
      "EXECUTION TIME: 9.68 seconds\n",
      "content=\"## The Enduring Pursuit of Independence: A Multifaceted Ideal\\n\\nIndependence, a word that resonates with power and promise, is a cornerstone of human aspiration. It signifies freedom from external control, the ability to make autonomous choices, and the capacity to shape one's own destiny. This concept, however, is far from monolithic. It manifests in diverse forms, from national sovereignty to personal autonomy, and its pursuit is a complex and often challenging journey. Understanding the multifaceted nature of independence, its historical significance, and its ongoing relevance in the modern world is crucial for navigating the complexities of individual and collective existence.\\n\\nAt its most fundamental level, independence refers to the state of being free from the domination or influence of others. This can apply to nations, individuals, or even organizations. National independence, often achieved through revolution or negotiated settlement, represents the liberation of a people from foreign rule. It entails the right to self-governance, the ability to determine one's own laws and policies, and the freedom to chart one's own economic and social course. The American Revolution, the Indian independence movement, and the dismantling of colonial empires across Africa and Asia stand as powerful testaments to the enduring human desire for national self-determination. These struggles, often marked by immense sacrifice and hardship, underscore the profound value placed on the right to govern oneself without external interference.\\n\\nHowever, national independence is not merely a political achievement; it is also a cultural and economic imperative. A truly independent nation must cultivate its own unique identity, preserving its traditions, language, and artistic expressions. It must also strive for economic self-sufficiency, developing its own industries and resources to avoid dependence on foreign powers. This requires strategic planning, investment in education and infrastructure, and a commitment to fostering innovation and entrepreneurship. Without economic and cultural autonomy, national independence remains incomplete, vulnerable to subtle forms of influence and control.\\n\\nBeyond the realm of nations, independence is equally vital at the individual level. Personal independence encompasses the ability to make one's own decisions, to pursue one's own goals, and to live life according to one's own values. This requires a degree of financial security, emotional maturity, and intellectual freedom. Individuals who are financially dependent on others, emotionally manipulated, or intellectually stifled are limited in their ability to exercise true independence.\\n\\nThe path to personal independence is often fraught with challenges. Societal expectations, familial pressures, and economic constraints can all hinder the development of autonomy. Overcoming these obstacles requires self-awareness, resilience, and a willingness to challenge conventional norms. Education plays a crucial role in fostering personal independence, equipping individuals with the critical thinking skills and knowledge necessary to make informed decisions. Furthermore, access to opportunities, such as education, employment, and healthcare, is essential for empowering individuals to achieve financial security and pursue their aspirations.\\n\\nThe concept of independence is not without its complexities and potential pitfalls. An overemphasis on individual autonomy can lead to isolation and a disregard for the needs of others. True independence is not about severing all ties with society but rather about forging meaningful connections based on mutual respect and shared values. Similarly, national independence should not be equated with isolationism or protectionism. In an increasingly interconnected world, cooperation and collaboration are essential for addressing global challenges such as climate change, poverty, and disease.\\n\\nFurthermore, the pursuit of independence must be tempered with a recognition of interdependence. No individual or nation is entirely self-sufficient. We rely on each other for goods, services, knowledge, and support. Recognizing this interdependence is not a sign of weakness but rather a recognition of the interconnectedness of human existence. True independence lies in the ability to navigate this complex web of relationships while maintaining one's own autonomy and integrity.\\n\\nThe digital age presents both opportunities and challenges to the pursuit of independence. On the one hand, the internet provides access to information and resources that can empower individuals and nations to make informed decisions and pursue their goals. Online education, remote work opportunities, and access to global markets can all contribute to greater independence. On the other hand, the digital age also poses new threats to autonomy. Data privacy concerns, the spread of misinformation, and the increasing influence of social media platforms can all undermine individual and national sovereignty.\\n\\nNavigating these challenges requires a critical and discerning approach to technology. Individuals must be vigilant about protecting their personal data and avoiding the echo chambers of social media. Nations must develop policies to regulate the digital sphere and protect their citizens from cyber threats. The key is to harness the power of technology to promote independence while mitigating its potential risks.\\n\\nIn conclusion, independence is a multifaceted ideal that encompasses national sovereignty, personal autonomy, and economic self-sufficiency. Its pursuit is a complex and ongoing process, fraught with challenges and requiring a delicate balance between individual freedom and collective responsibility. While the specific manifestations of independence may vary across cultures and contexts, the underlying principle remains constant: the right to self-determination, the ability to shape one's own destiny, and the freedom to live life according to one's own values. In an increasingly interconnected and rapidly changing world, the enduring pursuit of independence remains a vital imperative for individuals and nations alike. It is a testament to the human spirit's unwavering desire for freedom, autonomy, and the power to shape a better future. The challenge lies in understanding its complexities, navigating its potential pitfalls, and harnessing its transformative power to create a more just and equitable world for all.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--27e6b3fe-1803-4a11-94b4-d7ad9c6799ff-0' usage_metadata={'input_tokens': 14, 'output_tokens': 1100, 'total_tokens': 1114, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "query=\"can you give me 1000 words essay on independence?\"\n",
    "response = cached_model(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fa36a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CACHE HIT***\n",
      "EXECUTION TIME: 0.00 seconds\n",
      "content=\"## The Enduring Pursuit of Independence: A Multifaceted Ideal\\n\\nIndependence, a word that resonates with power and promise, is a cornerstone of human aspiration. It signifies freedom from external control, the ability to make autonomous choices, and the capacity to shape one's own destiny. This concept, however, is far from monolithic. It manifests in diverse forms, from national sovereignty to personal autonomy, and its pursuit is a complex and often challenging journey. Understanding the multifaceted nature of independence, its historical significance, and its ongoing relevance in the modern world is crucial for navigating the complexities of individual and collective existence.\\n\\nAt its most fundamental level, independence refers to the state of being free from the domination or influence of others. This can apply to nations, individuals, or even organizations. National independence, often achieved through revolution or negotiated settlement, represents the liberation of a people from foreign rule. It entails the right to self-governance, the ability to determine one's own laws and policies, and the freedom to chart one's own economic and social course. The American Revolution, the Indian independence movement, and the dismantling of colonial empires across Africa and Asia stand as powerful testaments to the enduring human desire for national self-determination. These struggles, often marked by immense sacrifice and hardship, underscore the profound value placed on the right to govern oneself without external interference.\\n\\nHowever, national independence is not merely a political achievement; it is also a cultural and economic imperative. A truly independent nation must cultivate its own unique identity, preserving its traditions, language, and artistic expressions. It must also strive for economic self-sufficiency, developing its own industries and resources to avoid dependence on foreign powers. This requires strategic planning, investment in education and infrastructure, and a commitment to fostering innovation and entrepreneurship. Without economic and cultural autonomy, national independence remains incomplete, vulnerable to subtle forms of influence and control.\\n\\nBeyond the realm of nations, independence is equally vital at the individual level. Personal independence encompasses the ability to make one's own decisions, to pursue one's own goals, and to live life according to one's own values. This requires a degree of financial security, emotional maturity, and intellectual freedom. Individuals who are financially dependent on others, emotionally manipulated, or intellectually stifled are limited in their ability to exercise true independence.\\n\\nThe path to personal independence is often fraught with challenges. Societal expectations, familial pressures, and economic constraints can all hinder the development of autonomy. Overcoming these obstacles requires self-awareness, resilience, and a willingness to challenge conventional norms. Education plays a crucial role in fostering personal independence, equipping individuals with the critical thinking skills and knowledge necessary to make informed decisions. Furthermore, access to opportunities, such as education, employment, and healthcare, is essential for empowering individuals to achieve financial security and pursue their aspirations.\\n\\nThe concept of independence is not without its complexities and potential pitfalls. An overemphasis on individual autonomy can lead to isolation and a disregard for the needs of others. True independence is not about severing all ties with society but rather about forging meaningful connections based on mutual respect and shared values. Similarly, national independence should not be equated with isolationism or protectionism. In an increasingly interconnected world, cooperation and collaboration are essential for addressing global challenges such as climate change, poverty, and disease.\\n\\nFurthermore, the pursuit of independence must be tempered with a recognition of interdependence. No individual or nation is entirely self-sufficient. We rely on each other for goods, services, knowledge, and support. Recognizing this interdependence is not a sign of weakness but rather a recognition of the interconnectedness of human existence. True independence lies in the ability to navigate this complex web of relationships while maintaining one's own autonomy and integrity.\\n\\nThe digital age presents both opportunities and challenges to the pursuit of independence. On the one hand, the internet provides access to information and resources that can empower individuals and nations to make informed decisions and pursue their goals. Online education, remote work opportunities, and access to global markets can all contribute to greater independence. On the other hand, the digital age also poses new threats to autonomy. Data privacy concerns, the spread of misinformation, and the increasing influence of social media platforms can all undermine individual and national sovereignty.\\n\\nNavigating these challenges requires a critical and discerning approach to technology. Individuals must be vigilant about protecting their personal data and avoiding the echo chambers of social media. Nations must develop policies to regulate the digital sphere and protect their citizens from cyber threats. The key is to harness the power of technology to promote independence while mitigating its potential risks.\\n\\nIn conclusion, independence is a multifaceted ideal that encompasses national sovereignty, personal autonomy, and economic self-sufficiency. Its pursuit is a complex and ongoing process, fraught with challenges and requiring a delicate balance between individual freedom and collective responsibility. While the specific manifestations of independence may vary across cultures and contexts, the underlying principle remains constant: the right to self-determination, the ability to shape one's own destiny, and the freedom to live life according to one's own values. In an increasingly interconnected and rapidly changing world, the enduring pursuit of independence remains a vital imperative for individuals and nations alike. It is a testament to the human spirit's unwavering desire for freedom, autonomy, and the power to shape a better future. The challenge lies in understanding its complexities, navigating its potential pitfalls, and harnessing its transformative power to create a more just and equitable world for all.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--27e6b3fe-1803-4a11-94b4-d7ad9c6799ff-0' usage_metadata={'input_tokens': 14, 'output_tokens': 1100, 'total_tokens': 1114, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "query=\"can you give me 1000 words essay on independence?\"\n",
    "response = cached_model(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e94798c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2025-08-25T16:21:04.178817Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Model Loaded: client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000204C87D3D00> async_client=<google.ai.generativelanguage_v1beta.services.generative_service.async_client.GenerativeServiceAsyncClient object at 0x00000204C8828EB0> model='models/text-embedding-004' task_type=None google_api_key=SecretStr('**********') credentials=None client_options=None transport=None request_options=None\n",
      "Embedding Result: [0.012455824762582779, -0.022220758721232414, -0.050555989146232605, -0.04617856815457344, 0.007134224288165569, 0.03131191432476044, 0.03413437679409981, 0.002971651265397668, -0.010995007120072842, 0.04237418621778488, -0.01806010864675045, 0.02493678405880928, 0.1121494323015213, -0.013102629221975803, -0.0148635134100914, -0.024023527279496193, 0.010264375247061253, -0.0037090936675667763, -0.10687677562236786, -0.001329770078882575, 0.03868139907717705, -0.03769991546869278, 0.03614252060651779, 0.005920442286878824, -0.04356273636221886, -0.004675108939409256, -0.023465346544981003, -0.010386619716882706, 0.011209390126168728, -0.025817539542913437, 0.04684286192059517, 0.08373904973268509, 0.010084772482514381, -0.03376094251871109, 0.020884841680526733, 0.02289341762661934, -0.003998701926320791, 0.01330992579460144, 0.0509757325053215, -0.09198947250843048, -0.07254136353731155, 0.04478190466761589, -0.0014892473118379712, 0.03480713814496994, -0.002893605502322316, -0.021368319168686867, 0.026944760233163834, 0.03481404110789299, -0.0113154212012887, 0.04239237308502197, 0.028903041034936905, 0.022403204813599586, -0.05002392828464508, 0.006107809022068977, -0.006879379041492939, -0.0005574015085585415, 0.00018034980166703463, 0.008374546654522419, 0.04145769402384758, -0.025920633226633072, 0.00581536628305912, 0.007453762460500002, -0.015612686984241009, -0.03611474484205246, 0.014897655695676804, -0.037706803530454636, 0.011048460379242897, -0.005773257464170456, -0.07338972389698029, 0.041947416961193085, -0.008714448660612106, 0.013749705627560616, -0.05058510601520538, 0.008701021783053875, -0.026075800880789757, -0.010403540916740894, -0.010278790257871151, -0.005401624366641045, 0.011471167206764221, 0.033857714384794235, -0.04043952003121376, 0.015613697469234467, 0.06003198027610779, 0.07738664001226425, -0.023364201188087463, 0.029591014608740807, 0.01976163499057293, -0.06802070140838623, -0.05220983177423477, -0.010016380809247494, 0.10859932005405426, 0.011279468424618244, 0.007659756112843752, -0.015049867331981659, 0.06771127879619598, -0.01944717764854431, -0.08944784849882126, -0.10393165796995163, 0.11675474792718887, 0.007203542161732912, 0.0008657867438159883, 0.007421628572046757, -0.009653370827436447, -0.06819561868906021, 0.01945577934384346, 0.051638804376125336, -0.029942573979496956, -0.042958736419677734, -0.019864805042743683, 0.017653953284025192, -0.017503488808870316, -0.044733524322509766, 0.03494996204972267, -0.0019917881581932306, -0.007429750170558691, 0.023747682571411133, -0.0431840755045414, 0.0019314548699185252, -0.03294016048312187, 0.014468812383711338, -0.0024643908254802227, 0.025144264101982117, -0.022134527564048767, 0.10755819827318192, 0.02490936405956745, 0.011192023754119873, 0.0015716323396191, -0.02178562432527542, -0.06771239638328552, -0.049380138516426086, 0.08783523738384247, -0.023269586265087128, 0.009737566113471985, 0.032387129962444305, -0.052026230841875076, -0.01877208985388279, 0.06508863717317581, -0.05382818356156349, 0.039945654571056366, 0.014005248434841633, -0.004315309226512909, -0.05164776369929314, -0.039541348814964294, 0.00784064270555973, 0.008627673611044884, -0.018560588359832764, -0.01660410314798355, 0.06843478977680206, -0.04986061155796051, -0.009544438682496548, -0.043490778654813766, -0.01982610858976841, 0.05358990281820297, -0.05194596201181412, 0.00924274418503046, 0.022442573681473732, 0.054759472608566284, -0.03969776630401611, 0.04876459762454033, -0.012862351723015308, 0.04954301565885544, -0.07955924421548843, -0.04404660686850548, 0.015906522050499916, -0.01791670173406601, 0.005397598259150982, 0.0038055086042732, -0.036019161343574524, 0.013881949707865715, 0.016763104125857353, -0.034556448459625244, -0.05342577397823334, -0.01381685771048069, -0.15006470680236816, -0.019942589104175568, 0.002566175302490592, -0.02811739221215248, -0.020092783495783806, -0.015126613900065422, -0.018085237592458725, 0.10519368946552277, 0.021229058504104614, -0.019142627716064453, -0.07908312976360321, 0.006924382410943508, -0.015233058482408524, 0.026185274124145508, 0.024732710793614388, 0.060259416699409485, 0.041969891637563705, -0.026774421334266663, 0.00799805298447609, 0.011700641363859177, 0.0342189259827137, -0.03183373063802719, 0.011145621538162231, 0.03164193034172058, -0.04771155118942261, 0.026175597682595253, -0.0489879809319973, 0.06313765048980713, 0.020891299471259117, -0.020877251401543617, -0.012239369563758373, -0.030345018953084946, 0.03507860377430916, -0.05327361077070236, -0.07006189227104187, -0.025967419147491455, 0.006272461265325546, -0.018474698066711426, 0.01101798377931118, -0.026081660762429237, -0.04022398963570595, 0.037948720157146454, -0.00023168617917690426, 0.0676269382238388, -0.005176514387130737, 0.01971936598420143, -0.03912899270653725, 0.049724530428647995, 0.05640000104904175, 0.036826711148023605, 0.023012086749076843, 0.023907935246825218, -0.003595447400584817, -0.05384625121951103, 0.0001777269208105281, 0.009188906289637089, -0.05081622675061226, 0.011230272240936756, 0.016221387311816216, -0.010362103581428528, 0.030504271388053894, -0.06813428550958633, 0.045014530420303345, 0.046261951327323914, -0.019377881661057472, -0.011723337695002556, 0.012803950347006321, -0.030391035601496696, -0.0030907855834811926, 0.06818464398384094, 0.01678100973367691, 0.04427051916718483, -0.04993132874369621, 0.06181267648935318, 0.05030204355716705, 0.022441618144512177, -0.025567203760147095, -0.015064483508467674, -0.029366008937358856, -0.015265165828168392, 0.0031529932748526335, -0.08744263648986816, -0.016554730013012886, 0.033491041511297226, -0.004213474690914154, 0.0006747462321072817, -0.032266318798065186, 0.07835523039102554, -0.013851643539965153, -0.005762961693108082, -0.10156656801700592, -0.03644723445177078, -0.07768076658248901, -0.01030147634446621, 0.013028323650360107, 0.027633754536509514, -0.05577288940548897, 0.013342211954295635, -0.017482010647654533, -0.0411427803337574, 0.007647169288247824, -0.011470891535282135, 0.02215852402150631, 0.011031962931156158, 0.004099421203136444, -0.014440973289310932, -0.018185188993811607, 0.009319433942437172, 0.004363721702247858, 0.004475305322557688, 0.005963848903775215, 0.0012982389889657497, -0.07796481996774673, 0.003906753845512867, 0.023633567616343498, -0.027058854699134827, -0.000518499466124922, 0.05265210568904877, 0.05519836023449898, -0.0343669094145298, -0.02824120968580246, 0.016249554231762886, 0.0033043352887034416, 0.03540894016623497, 0.033357247710227966, -0.008044273592531681, -0.0029608916956931353, 0.024958647787570953, 0.050681307911872864, -0.037793662399053574, 0.04992763698101044, 0.0032780796755105257, -0.009910456836223602, -0.029421841725707054, -0.0147116519510746, -0.021794697269797325, 0.03465849161148071, -0.036990948021411896, 0.03658265620470047, -0.030192671343684196, -0.0320877879858017, -0.03083866462111473, -0.01527484506368637, -0.16792982816696167, -0.013539016246795654, -0.0018505020998418331, -0.01373943779617548, 0.019737526774406433, 0.02806883677840233, -0.01974073424935341, 0.0017742604250088334, -0.0052481759339571, -0.01596209593117237, 0.007207742426544428, -0.007615270093083382, 0.006253538653254509, 0.01837211474776268, 0.012095113284885883, 0.005751940421760082, -0.04393688589334488, -0.0458187460899353, 0.016736146062612534, 0.026165161281824112, -0.06021394580602646, 0.012089228257536888, 0.06863582134246826, 0.055838871747255325, 0.0484868586063385, 0.04481371119618416, 0.04715169966220856, 0.01655426062643528, -0.020898090675473213, -0.05972684919834137, -0.053977467119693756, 0.007847784087061882, 0.03233913332223892, 0.010286054573953152, 0.018272725865244865, 0.05693472921848297, 0.026759905740618706, -0.053598854690790176, -0.01714101992547512, -0.017183609306812286, 0.055396780371665955, 0.0011198350694030523, 0.027947822585701942, 0.004425154998898506, 0.011749014258384705, 0.0153060806915164, 0.005009829066693783, 0.010540829040110111, 0.048252787441015244, -0.006977658718824387, 0.011299684643745422, 0.03948843851685524, -0.009677493944764137, -0.05354953929781914, -0.008452726528048515, 0.00911550410091877, -0.01360390242189169, -0.025395328179001808, 0.031119374558329582, -0.01998763158917427, -0.05207986384630203, 0.016682274639606476, -0.015195782296359539, 0.017817987129092216, -0.005787302274256945, -0.009513536468148232, -0.01888391375541687, 0.006778006907552481, -0.03996298462152481, 0.07906286418437958, -0.04934483394026756, 0.002534460509195924, -0.0013140749651938677, 0.009739372879266739, -0.018827378749847412, 0.09211372584104538, 0.02701706625521183, 0.010106097906827927, 0.013180524110794067, 0.05087077245116234, -0.029946329072117805, 0.012760140001773834, -0.012855489738285542, 0.008200105279684067, 0.010300644673407078, -0.03887227177619934, 0.087727852165699, -0.058080825954675674, -0.013879751786589622, -0.02160850167274475, 0.05208851397037506, -0.019328616559505463, 0.003200874198228121, 0.011286824941635132, -0.0064423275180161, -0.020448535680770874, -0.018702432513237, 0.026471124961972237, -0.033904481679201126, -0.010618172585964203, 0.025642720982432365, -0.0313863642513752, -0.011534960940480232, 0.007908572442829609, -0.04512445256114006, 0.02283351682126522, 0.009164620190858841, -0.03853495419025421, -0.0023934936616569757, -0.051996540278196335, -0.010612817481160164, 0.04071998968720436, -0.00025710684712976217, -0.024372100830078125, 0.045417264103889465, 0.07408653944730759, 0.003408790100365877, 0.08287716656923294, 0.04879200458526611, 0.050907570868730545, 0.010100091807544231, 0.0189394261687994, 0.013357345014810562, 0.010168148204684258, -0.035304151475429535, 0.002700807061046362, 0.05240805447101593, 0.020336272194981575, -0.012393375858664513, 0.07442007958889008, 0.06263931095600128, 0.04272599145770073, -0.02711469493806362, -0.004798205569386482, 0.013068271800875664, -0.02986450120806694, 0.00037538332981057465, 0.013057507574558258, -0.0968465507030487, -0.01798231340944767, 0.012189477682113647, 0.03501345217227936, -0.011081080883741379, -0.01745767891407013, -0.031983938068151474, -0.022064335644245148, 0.08485711365938187, -0.00343685457482934, -0.01456260122358799, 0.005010343622416258, -0.007688052020967007, 0.024608660489320755, -0.08292613178491592, 0.06397508084774017, 0.004690829198807478, 0.007913096807897091, 0.036022353917360306, 0.0006659068749286234, -0.01658443920314312, -0.018636764958500862, 0.024615516886115074, 0.02414553053677082, -0.06473634392023087, -0.009792412631213665, -0.05325734615325928, 0.01420909259468317, -0.039277199655771255, 0.023884374648332596, 0.05650574713945389, -0.02766450308263302, -0.024189328774809837, 0.029870592057704926, -0.032924309372901917, 0.019669799134135246, -0.018359094858169556, 0.018801331520080566, -0.02707786299288273, -0.020441895350813866, 0.004687879700213671, 0.002401745645329356, 0.06377092003822327, -0.04281676188111305, -0.0009759454987943172, 0.027595609426498413, 0.060424257069826126, 0.020918354392051697, -0.005486592650413513, -0.07342268526554108, -0.0526941753923893, 0.029353946447372437, -0.03353140875697136, -0.004850347992032766, 0.04146687686443329, -0.026472879573702812, 0.01267069112509489, -0.00446405028924346, 0.010773347690701485, 0.0038922347594052553, -0.01121237687766552, 0.0022828769870102406, -0.03537539765238762, 0.014624923467636108, -0.022506799548864365, 0.042016711086034775, -0.06862662732601166, -0.013486203737556934, 0.028224986046552658, 0.002582587068900466, 0.03553735837340355, -0.015434455126523972, -0.014334972016513348, 0.004324035253375769, 0.0053898063488304615, -0.07821765542030334, -0.004852551035583019, 0.058350931853055954, 0.05561845749616623, 0.04971618577837944, 0.00848366692662239, 0.019691959023475647, 0.04842359572649002, 0.016710050404071808, -0.036617863923311234, 0.046702999621629715, -0.023141957819461823, -0.014032494276762009, -0.004935077391564846, 0.017640557140111923, 0.05168399587273598, -0.008145507425069809, 0.003850450273603201, 0.07378315180540085, -0.025645993649959564, 0.06141502037644386, -0.005647069774568081, -0.03568589314818382, -0.012221494689583778, -0.019573714584112167, -0.010537681169807911, 0.00864588562399149, 0.020921990275382996, -0.04302797093987465, -0.020178483799099922, -0.028311334550380707, 0.009283555671572685, -0.02459694817662239, 0.024087658151984215, -0.004313063342124224, -0.005432801321148872, -0.013785123825073242, 0.024139773100614548, 0.05857562646269798, -0.03191772848367691, 0.012416687794029713, 0.016925476491451263, 0.006942843087017536, 0.006598522886633873, -0.0390513651072979, -0.007005717605352402, -8.729863475309685e-05, -0.04538340121507645, 0.004946487955749035, 0.029524078592658043, -0.034420207142829895, -0.004038716200739145, -0.008144606836140156, 0.027810344472527504, 0.0006213292945176363, 0.012055370956659317, 0.0009448639466427267, 0.0028901349287480116, -0.015417925082147121, 0.015339858829975128, -0.015768028795719147, 0.007656121626496315, 0.03895176202058792, -0.011974029242992401, -0.03488216921687126, 0.0021897954866290092, 0.008017251268029213, -0.023602457717061043, 0.042762432247400284, 0.017669593915343285, 0.02949250116944313, -0.004777966067194939, 0.01222960278391838, 0.04622475057840347, 0.004831378813832998, 0.005080347880721092, -0.03096405789256096, -0.024769319221377373, -0.05760312080383301, 0.006989185232669115, -0.02802259847521782, 0.0023186085745692253, 0.024799270555377007, -0.017475241795182228, -0.02310723438858986, -0.060716282576322556, -0.05141041800379753, -0.08543168753385544, -0.031041642650961876, 0.0007977064815349877, 0.00771120423451066, -0.014823099598288536, 0.017547423020005226, 0.028314258903265, -0.01559355203062296, -0.06470701843500137, 0.022269032895565033, -0.0012528174556791782, 0.003755373414605856, 0.02596835233271122, -0.014884010888636112, -0.016153506934642792, 0.012660589069128036, 0.051579441875219345, -0.026004411280155182, -0.010785234160721302, 0.024741262197494507, -0.006832896266132593, 0.006077229045331478, -0.018859494477510452, -0.04515213519334793, -0.015692224726080894, 0.02197863720357418, 0.027596719563007355, 0.013474834151566029, -0.06793735921382904, 0.03974653407931328, 0.029159316793084145, 0.009424426592886448, 0.036018598824739456, 0.06579939275979996, 0.0007757350686006248, 0.026988979429006577, -0.023084744811058044, 0.005725073162466288, -0.009881219826638699, 0.04924647510051727, -0.04520491138100624, 0.0036490694619715214, -0.0001661169226281345, 0.01312621496617794, 0.032258667051792145, -0.04117229953408241, -0.0017563514411449432, 0.005697781685739756, -0.004057110287249088, 0.00831490196287632, -0.01355521846562624, 0.017786549404263496, 0.019952373579144478, -0.017415044829249382, 0.02924727275967598, 0.00436373008415103, -0.028496161103248596, -0.0003454386896919459, -0.028011614456772804, 0.030717402696609497, 0.029748037457466125, 0.0013926341198384762, -0.029566174373030663, 0.022096160799264908, -0.01822168380022049, -0.03222834691405296, 0.005902382079511881, -0.036765407770872116, 0.008787472732365131, -0.02015107311308384, 0.06050626561045647, -0.01662573777139187, -0.024680834263563156, 0.04925467446446419, 0.027687592431902885, -0.0594508983194828, -0.03355632722377777, -0.0018203321378678083, -0.013882149010896683, 0.03436409682035446, -0.006525041069835424, 0.02155226469039917, -0.068003810942173, 0.009525789879262447, -0.055456023663282394, -0.0006107259541749954, -0.056682657450437546, -0.03278589993715286, 0.039782535284757614, -0.0029560134280472994, 0.04285448044538498, 0.015113752335309982, -0.006758872419595718, -0.005822359584271908, -0.023287208750844002, 0.01268066093325615, 0.006393882911652327, 0.005613046232610941, -0.024748165160417557, 0.04511215165257454, 0.028768694028258324, 0.01948765106499195, 0.02212745137512684, -0.023323310539126396, 0.00483762426301837, -0.004555167630314827, 0.0469304658472538, 0.06336293369531631, 0.06120479479432106, 0.024199720472097397, -0.07068958878517151, -0.023261142894625664, -0.03503222018480301, 0.07099641114473343, 0.07402566820383072, -0.022733237594366074, -0.013286171481013298, 0.013622286729514599, -0.021212313324213028, -0.022044561803340912, -0.005962895229458809, -0.033503927290439606, -0.02475627325475216, -0.042249567806720734, 0.02494623139500618, -0.0562412291765213, -0.09909646958112717, -0.03917242959141731, -0.021050311625003815, -0.006634335964918137, -0.020698025822639465, -0.003643974894657731, -0.027524033561348915, -0.031454574316740036, -0.06287893652915955, 0.005579663440585136, -0.015219196677207947, 0.0010854346910491586, 0.03304031863808632, -0.011660171672701836, -0.030525514855980873, 0.00619041221216321, 0.028455788269639015, 0.04060158133506775, -0.036002323031425476, 0.09819784760475159, 0.001239479286596179, 0.0327460952103138, -0.05798015370965004, -0.03414849564433098, 0.033689990639686584, -0.03496948629617691]\n"
     ]
    }
   ],
   "source": [
    "embedding_model = loader.load_embeddings()\n",
    "print(f\"Embedding Model Loaded: {embedding_model}\")\n",
    "result = embedding_model.embed_query(\"Hello, how are you?\")\n",
    "print(f\"Embedding Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0e18a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d052719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=\"The Earth is the third planet from the Sun and the only known planet to support life. It has a diverse climate, ranging from arctic to tropical zones, and supports ecosystems across seven continents and five oceans.\"),\n",
    "\n",
    "    Document(page_content=\"The Industrial Revolution, beginning in the 18th century, drastically transformed human societies by shifting from manual labor to machine-based manufacturing, leading to urbanization and economic expansion globally.\"),\n",
    "\n",
    "    Document(page_content=\"The United Nations, established in 1945 after World War II, is an international organization founded to promote peace, security, human rights, and cooperation among countries. It has 193 member states.\"),\n",
    "\n",
    "    Document(page_content=\"The global economy is an interconnected system involving trade, investment, and financial flows across countries. Major players include the United States, China, the European Union, and emerging markets like India and Brazil.\"),\n",
    "\n",
    "    Document(page_content=\"Climate change refers to long-term shifts in temperatures and weather patterns. It is largely driven by human activities like burning fossil fuels, deforestation, and industrial emissions, leading to global warming and sea level rise.\"),\n",
    "\n",
    "    Document(page_content=\"Democracy is a political system in which citizens exercise power by voting. Modern democracies typically have institutions for free elections, rule of law, freedom of expression, and checks and balances.\"),\n",
    "\n",
    "    Document(page_content=\"The Internet has revolutionized communication, commerce, and education worldwide. Originating from military research in the 1960s, it now connects over 5 billion people, enabling instant global information exchange.\"),\n",
    "\n",
    "    Document(page_content=\"Renewable energy sources like solar, wind, hydro, and geothermal are critical for a sustainable future. They offer alternatives to fossil fuels, reducing carbon emissions and reliance on finite resources.\"),\n",
    "\n",
    "    Document(page_content=\"The World Health Organization (WHO) is a UN agency focused on global health issues. It coordinates international efforts to monitor diseases, set health standards, and respond to pandemics like COVID-19.\"),\n",
    "\n",
    "    Document(page_content=\"Globalization is the process of increasing interaction and integration among people, companies, and governments worldwide. It has led to greater economic growth but also raised concerns about inequality and cultural homogenization.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cae44b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "# Chroma vector DB with persistent storage\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./chroma_db\"  # Disk path for persistence\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20289e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gunas\\AppData\\Local\\Temp\\ipykernel_16180\\1854114808.py:2: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vector_store.persist()\n"
     ]
    }
   ],
   "source": [
    "# Optional: Persist manually (though auto-persistence happens internally)\n",
    "vector_store.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "175a06db",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a312baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Use the following context to answer the question.\n",
    "    If you don't know the answer, just say you don't know. Don't try to make up an answer.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5c61784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCEL RAG Chain step-by-step\n",
    "rag_chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": retriever | (lambda docs: \"\\n\\n\".join([doc.page_content for doc in docs])),\n",
    "        \"question\": RunnablePassthrough()\n",
    "    })\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2a5fa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap with cache\n",
    "RAG_Cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a649beab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def cached_rag_chain(query):\n",
    "    start_time = time.time()\n",
    "    if RAG_Cache.get(query):\n",
    "        print(\"***CACHE HIT***\")\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(f\"EXECUTION TIME: {elapsed:.2f} seconds\")\n",
    "        return RAG_Cache.get(query)\n",
    "    else:\n",
    "        print(\"***CACHE MISS – EXECUTING MODEL***\")\n",
    "        start_time = time.time()\n",
    "        response = llm.invoke(query)\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(f\"EXECUTION TIME: {elapsed:.2f} seconds\")\n",
    "        RAG_Cache[query] = response\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "653b5977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CACHE MISS – EXECUTING MODEL***\n",
      "EXECUTION TIME: 8.25 seconds\n",
      "content='Okay, let\\'s break down the Japanese economy in 2024 and its relationship with North Korea.\\n\\n**Japan\\'s Economy in 2024: Overview**\\n\\nJapan\\'s economy in 2024 is characterized by a mix of challenges and opportunities. Here\\'s a summary:\\n\\n*   **Slow Growth:** Japan has been experiencing relatively slow economic growth for decades, and this trend is expected to continue in 2024. The IMF and other organizations project modest growth, typically in the range of 0.5% to 1%.\\n*   **Aging Population and Declining Birth Rate:** This is a major structural issue. A shrinking workforce puts pressure on the social security system, reduces consumption, and limits potential economic growth.\\n*   **Government Debt:** Japan has one of the highest levels of government debt in the world as a percentage of GDP. This limits the government\\'s ability to stimulate the economy through fiscal policy.\\n*   **Inflation:** After decades of deflation, Japan has been experiencing inflation, partly due to global factors like rising energy prices and supply chain disruptions. The Bank of Japan (BOJ) has been hesitant to aggressively raise interest rates to combat inflation, unlike many other central banks, due to concerns about stifling economic growth.\\n*   **Monetary Policy:** The Bank of Japan has maintained its ultra-loose monetary policy, including negative interest rates and yield curve control, in an attempt to stimulate the economy and achieve its inflation target. This policy has been controversial and has led to a weaker yen.\\n*   **Exports:** Japan is a major exporting nation, with key exports including automobiles, electronics, and machinery. Global economic conditions and trade relations significantly impact Japan\\'s export performance.\\n*   **Tourism:** Tourism has been recovering after the COVID-19 pandemic, providing a boost to the economy.\\n*   **Technological Innovation:** Japan remains a leader in many technological fields, including robotics, automation, and advanced materials. Innovation is seen as crucial for driving future economic growth.\\n*   **Corporate Governance Reforms:** There have been ongoing efforts to improve corporate governance in Japan, aiming to increase shareholder value and attract foreign investment.\\n\\n**Key Challenges:**\\n\\n*   **Demographic Decline:** Addressing the aging population and declining birth rate is a critical long-term challenge.\\n*   **Structural Reforms:** Implementing structural reforms to boost productivity and competitiveness is essential.\\n*   **Inflation Management:** Balancing the need to control inflation with the desire to support economic growth is a delicate task for the Bank of Japan.\\n*   **Geopolitical Risks:** Global geopolitical tensions, including those related to North Korea, can impact Japan\\'s economy.\\n\\n**Japan-North Korea Relations and Economic Impact**\\n\\nThe relationship between Japan and North Korea is complex and primarily characterized by tension and distrust. There are virtually no formal economic ties. Here\\'s how the relationship affects Japan\\'s economy:\\n\\n*   **Limited Direct Economic Impact:** Direct trade and investment between Japan and North Korea are minimal due to sanctions and political tensions. Therefore, the direct economic impact of North Korea on Japan\\'s economy is small.\\n*   **Security Concerns:** North Korea\\'s nuclear and missile programs pose a significant security threat to Japan. This necessitates increased defense spending and can affect investor confidence.\\n*   **Sanctions:** Japan has imposed sanctions on North Korea in response to its nuclear and missile tests. These sanctions further limit any potential economic interaction.\\n*   **Geopolitical Risk:** The ongoing tensions with North Korea contribute to geopolitical risk in the region, which can affect financial markets and investment decisions.\\n*   **\"Japan Premium\":** Some analysts argue that geopolitical risks, including those related to North Korea, can contribute to a \"Japan premium,\" where investors demand a higher return on investments in Japan to compensate for the perceived risk.\\n*   **Refugee Crisis:** While unlikely, a major crisis in North Korea could potentially lead to a refugee influx into Japan, which would have economic and social implications.\\n*   **Indirect Effects:** Broader geopolitical instability in East Asia, partly driven by North Korea, can affect global trade and supply chains, which in turn can impact Japan\\'s economy.\\n\\n**In summary:**\\n\\nWhile North Korea doesn\\'t have a large direct impact on Japan\\'s economy through trade or investment, the security threat it poses and the resulting geopolitical instability can have indirect effects on investor confidence, defense spending, and regional economic stability. Japan\\'s economic focus is much more on its relationships with major trading partners like the United States, China, and South Korea, as well as global economic trends.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--72d1f110-944b-45fa-960a-7e1adf622e7f-0' usage_metadata={'input_tokens': 16, 'output_tokens': 952, 'total_tokens': 968, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "query = \"what is japan economy in 2024 and relation with north korea?\"\n",
    "response = cached_rag_chain(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e08ea260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CACHE MISS – EXECUTING MODEL***\n",
      "EXECUTION TIME: 7.19 seconds\n",
      "content=\"LangChain is a framework designed to simplify the development of applications powered by large language models (LLMs). It provides tools, components, and interfaces to connect LLMs to various data sources and other computational resources, enabling developers to build more complex and sophisticated applications.\\n\\nHere's a breakdown of what LangChain is and its key features:\\n\\n**Core Concepts:**\\n\\n* **LLMs (Large Language Models):**  LangChain is built around the idea of leveraging the power of LLMs like GPT-3, GPT-4, PaLM, and others.  It provides a standardized interface for interacting with these models.\\n* **Components:** LangChain offers a collection of modular components that can be assembled to create different types of applications. These components include:\\n    * **Models:** Abstractions for different types of language models (LLMs, Chat Models, Text Embedding Models).\\n    * **Prompts:** Tools for constructing and managing prompts to guide the LLM's behavior.  This includes prompt templates, example selectors, and output parsers.\\n    * **Chains:** Sequences of calls to LLMs or other utilities.  Chains allow you to combine multiple steps into a single, coherent process.  Examples include:\\n        * **LLMChain:** A simple chain that runs an LLM on an input.\\n        * **SequentialChain:**  A chain that executes multiple chains in a specific order.\\n        * **RouterChain:** A chain that dynamically selects which chain to execute based on the input.\\n    * **Indexes:**  Ways to structure documents so that LLMs can best interact with them. This often involves embedding documents and storing them in a vector database.\\n    * **Memory:**  Mechanisms for storing and retrieving information from previous interactions, allowing LLMs to maintain context and have more meaningful conversations.  Examples include:\\n        * **ConversationBufferMemory:** Stores the entire conversation history.\\n        * **ConversationSummaryMemory:** Summarizes the conversation history to save space.\\n    * **Agents:**  Systems that use an LLM to decide which actions to take.  Agents can use tools to interact with the outside world (e.g., search the web, run code, access databases).\\n    * **Callbacks:**  Hooks that allow you to monitor and log the execution of LangChain components.\\n\\n**Key Features and Benefits:**\\n\\n* **Modularity:** LangChain is designed to be modular, allowing you to easily swap out different components and customize your applications.\\n* **Composability:**  You can combine different components to create complex chains and agents.\\n* **Standardized Interface:** LangChain provides a consistent interface for interacting with different LLMs, making it easier to switch between models.\\n* **Data Integration:**  LangChain provides tools for connecting LLMs to various data sources, such as databases, APIs, and documents.\\n* **Context Management:**  LangChain offers memory components to help LLMs maintain context and have more meaningful conversations.\\n* **Agent Capabilities:**  LangChain enables the creation of agents that can use tools to interact with the outside world.\\n* **Active Community:**  LangChain has a large and active community, providing support and contributing to the framework's development.\\n* **Open Source:** LangChain is open source, allowing you to contribute to the project and customize it to your specific needs.\\n\\n**Use Cases:**\\n\\nLangChain can be used to build a wide variety of applications, including:\\n\\n* **Chatbots:**  Create conversational agents that can answer questions, provide information, and perform tasks.\\n* **Question Answering Systems:**  Build systems that can answer questions based on a knowledge base of documents.\\n* **Text Summarization:**  Summarize long documents into shorter, more concise versions.\\n* **Code Generation:**  Generate code based on natural language descriptions.\\n* **Data Analysis:**  Analyze data and generate insights using natural language.\\n* **Personal Assistants:**  Create personal assistants that can help you with tasks such as scheduling appointments, setting reminders, and sending emails.\\n* **Document Analysis:** Extract information from documents, classify them, and perform other document-related tasks.\\n\\n**In summary, LangChain is a powerful framework that simplifies the development of LLM-powered applications by providing modular components, standardized interfaces, and tools for connecting LLMs to various data sources and computational resources.** It allows developers to focus on building the logic of their applications rather than dealing with the complexities of interacting with LLMs directly.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--9f7ff5f3-20ce-4742-a3e0-fca0521f926d-0' usage_metadata={'input_tokens': 6, 'output_tokens': 923, 'total_tokens': 929, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "query = \"what is langchain framework?\"\n",
    "response = cached_rag_chain(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df7bc6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CACHE MISS – EXECUTING MODEL***\n",
      "EXECUTION TIME: 5.06 seconds\n",
      "content=\"The United Nations was established in 1945 after World War II for a multitude of crucial reasons, all stemming from the desire to prevent another global catastrophe and foster international cooperation. Here's a breakdown of the key motivations:\\n\\n*   **Preventing Future Wars:** The primary and overarching goal was to prevent another world war. The devastation of World War I and especially World War II, with its unprecedented loss of life and widespread destruction, made it clear that a new international organization was needed to address the root causes of conflict and provide mechanisms for peaceful resolution.\\n\\n*   **Maintaining International Peace and Security:** The UN Charter explicitly states its purpose as maintaining international peace and security. This involves:\\n    *   **Collective Security:** The idea that if one member is attacked, the others will come to its defense (though this is more nuanced in practice).\\n    *   **Peacekeeping Operations:** Deploying UN forces to conflict zones to monitor ceasefires, stabilize situations, and protect civilians.\\n    *   **Conflict Prevention:** Addressing the underlying causes of conflict through diplomacy, mediation, and development assistance.\\n\\n*   **Promoting International Cooperation:** The UN aims to foster cooperation among nations on a wide range of issues, including:\\n    *   **Economic Development:** Working to reduce poverty, improve living standards, and promote sustainable development.\\n    *   **Social Progress:** Addressing issues such as human rights, gender equality, and health.\\n    *   **Cultural Exchange:** Promoting understanding and cooperation between different cultures.\\n\\n*   **Upholding Human Rights:** The Universal Declaration of Human Rights, adopted by the UN in 1948, sets out fundamental rights and freedoms for all people. The UN works to promote and protect these rights through various mechanisms, including:\\n    *   **Monitoring human rights situations around the world.**\\n    *   **Investigating human rights violations.**\\n    *   **Providing technical assistance to governments to improve their human rights record.**\\n\\n*   **Replacing the League of Nations:** The League of Nations, established after World War I, had failed to prevent World War II. It was seen as weak and ineffective, lacking the universal membership and enforcement powers necessary to maintain peace. The UN was designed to address the shortcomings of the League.\\n\\n*   **Establishing a Forum for Dialogue:** The UN provides a forum where all nations, regardless of size or power, can come together to discuss issues of common concern. This allows for dialogue, negotiation, and the potential for finding common ground.\\n\\n*   **Addressing Global Challenges:** The UN recognizes that many challenges facing the world, such as climate change, pandemics, and poverty, require international cooperation to address effectively.\\n\\nIn summary, the United Nations was established in the aftermath of World War II as a response to the horrors of the war and a recognition that international cooperation was essential for preventing future conflicts, promoting peace and security, and addressing global challenges. It was intended to be a more effective and universal organization than its predecessor, the League of Nations, with a broader mandate and stronger enforcement powers.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--e8f08251-04fb-4e5b-8fcd-9c966f053ffb-0' usage_metadata={'input_tokens': 16, 'output_tokens': 627, 'total_tokens': 643, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "query = \"Why United Nations, established in 1945 after World War II?\"\n",
    "response = cached_rag_chain(query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89879ae",
   "metadata": {},
   "source": [
    "# Cache Using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3fac93d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import InMemoryCache\n",
    "from langchain.globals import set_llm_cache\n",
    "from typing import Any, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "016eba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DebuggableCache(InMemoryCache):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._cache: Dict[Tuple[str, str], Any] = {}\n",
    "\n",
    "    def lookup(self, prompt: str, llm_string: str):\n",
    "        return self._cache.get((prompt, llm_string))\n",
    "\n",
    "    def update(self, prompt: str, llm_string: str, return_val: Any):\n",
    "        self._cache[(prompt, llm_string)] = return_val\n",
    "\n",
    "    def view_cache(self):  # this is our custom method\n",
    "        return self._cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a41db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbg_cache = DebuggableCache()\n",
    "set_llm_cache(dbg_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bdcfea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed2b85a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: content='The capital of France is **Paris**.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--19e77678-4cd2-47df-a116-6d0a426c4890-0' usage_metadata={'input_tokens': 7, 'output_tokens': 9, 'total_tokens': 16, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(\"LLM Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebfa4088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cache Contents:\n",
      "Prompt: [{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"HumanMessage\"], \"kwargs\": {\"content\": \"What is the capital of France?\", \"type\": \"human\"}}] | Cached Output: [ChatGeneration(text='The capital of France is **Paris**.', generation_info={'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, message=AIMessage(content='The capital of France is **Paris**.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--19e77678-4cd2-47df-a116-6d0a426c4890-0', usage_metadata={'input_tokens': 7, 'output_tokens': 9, 'total_tokens': 16, 'input_token_details': {'cache_read': 0}}))]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCache Contents:\")\n",
    "for k, v in dbg_cache.view_cache().items():\n",
    "    print(f\"Prompt: {k[0]} | Cached Output: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5c3d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e79df963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cache Contents:\n",
      "Prompt: [{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"HumanMessage\"], \"kwargs\": {\"content\": \"What is the capital of France?\", \"type\": \"human\"}}] | Cached Output: [ChatGeneration(text='The capital of France is **Paris**.', generation_info={'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, message=AIMessage(content='The capital of France is **Paris**.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--19e77678-4cd2-47df-a116-6d0a426c4890-0', usage_metadata={'input_tokens': 7, 'output_tokens': 9, 'total_tokens': 16, 'input_token_details': {'cache_read': 0}}))]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCache Contents:\")\n",
    "for k, v in dbg_cache.view_cache().items():\n",
    "    print(f\"Prompt: {k[0]} | Cached Output: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f011e6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: content='The capital of India is **New Delhi**.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--bbc1dfbc-992b-419b-9061-a89e23f0cdc2-0' usage_metadata={'input_tokens': 7, 'output_tokens': 10, 'total_tokens': 17, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"What is the capital of india?\")\n",
    "print(\"LLM Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ed08be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cache Contents:\n",
      "Prompt: [{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"HumanMessage\"], \"kwargs\": {\"content\": \"What is the capital of France?\", \"type\": \"human\"}}] | Cached Output: [ChatGeneration(text='The capital of France is **Paris**.', generation_info={'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, message=AIMessage(content='The capital of France is **Paris**.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--19e77678-4cd2-47df-a116-6d0a426c4890-0', usage_metadata={'input_tokens': 7, 'output_tokens': 9, 'total_tokens': 16, 'input_token_details': {'cache_read': 0}}))]\n",
      "Prompt: [{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"HumanMessage\"], \"kwargs\": {\"content\": \"What is the capital of india?\", \"type\": \"human\"}}] | Cached Output: [ChatGeneration(text='The capital of India is **New Delhi**.', generation_info={'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, message=AIMessage(content='The capital of India is **New Delhi**.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--bbc1dfbc-992b-419b-9061-a89e23f0cdc2-0', usage_metadata={'input_tokens': 7, 'output_tokens': 10, 'total_tokens': 17, 'input_token_details': {'cache_read': 0}}))]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCache Contents:\")\n",
    "for k, v in dbg_cache.view_cache().items():\n",
    "    print(f\"Prompt: {k[0]} | Cached Output: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c426c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: content='The capital of India is **New Delhi**.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--bbc1dfbc-992b-419b-9061-a89e23f0cdc2-0' usage_metadata={'input_tokens': 7, 'output_tokens': 10, 'total_tokens': 17, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"What is the capital of india?\")\n",
    "print(\"LLM Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9d2c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: content=\"## The Indelible Bond: Science, Mathematics, and the Pursuit of Understanding\\n\\nScience, in its broadest sense, is the systematic pursuit of knowledge about the natural world through observation, experimentation, and analysis. It is a dynamic and ever-evolving process, driven by curiosity and a desire to understand the intricate workings of the universe. From the smallest subatomic particles to the vast expanse of galaxies, science seeks to unravel the mysteries that surround us, providing explanations and predictions that shape our understanding of reality. At the heart of this endeavor lies a powerful and indispensable tool: mathematics. Mathematics provides the language, the structure, and the logical framework that allows science to move beyond mere observation and into the realm of quantifiable understanding and predictive power. The relationship between science and mathematics is not merely symbiotic; it is a fundamental and inseparable bond, a cornerstone upon which our modern understanding of the world is built.\\n\\nThe importance of mathematics to science stems from its ability to provide a precise and unambiguous language for describing natural phenomena. Unlike everyday language, which is often vague and subjective, mathematics offers a rigorous and objective system of symbols and rules that can be used to represent and manipulate complex concepts. This precision is crucial for formulating scientific theories and hypotheses, which must be testable and falsifiable. Without the language of mathematics, scientific ideas would remain abstract and difficult to communicate, hindering progress and collaboration.\\n\\nConsider, for example, the laws of motion formulated by Isaac Newton. These laws, which describe the relationship between force, mass, and acceleration, are expressed in the form of mathematical equations. These equations allow us to predict the motion of objects with remarkable accuracy, from the trajectory of a baseball to the orbit of a planet. Without the mathematical framework provided by calculus and algebra, Newton's laws would be nothing more than qualitative observations, lacking the predictive power that makes them so fundamental to physics.\\n\\nSimilarly, in chemistry, the understanding of chemical reactions relies heavily on mathematical concepts such as stoichiometry and thermodynamics. Stoichiometry allows us to calculate the amounts of reactants and products involved in a chemical reaction, ensuring that we can carry out experiments safely and efficiently. Thermodynamics, on the other hand, provides a mathematical framework for understanding the energy changes that accompany chemical reactions, allowing us to predict whether a reaction will occur spontaneously and how much energy it will release or absorb.\\n\\nIn biology, mathematics plays an increasingly important role in understanding complex biological systems. From modeling population dynamics to analyzing genetic data, mathematical tools are essential for making sense of the vast amounts of information generated by modern biological research. For example, mathematical models are used to study the spread of infectious diseases, allowing public health officials to develop effective strategies for controlling outbreaks. Similarly, mathematical algorithms are used to analyze DNA sequences, identifying genes that are associated with specific diseases and developing personalized treatments.\\n\\nThe importance of mathematics to science extends beyond simply providing a language for describing natural phenomena. Mathematics also provides a powerful set of tools for analyzing data and drawing conclusions. Statistical methods, for example, are used to analyze experimental data, allowing scientists to determine whether their results are statistically significant and to draw meaningful conclusions from their observations. Without statistical analysis, it would be impossible to distinguish between genuine effects and random variations, making it difficult to draw reliable conclusions from scientific experiments.\\n\\nFurthermore, mathematics provides the foundation for developing computational models and simulations, which are increasingly used in science to study complex systems that are difficult or impossible to study experimentally. For example, climate models are used to simulate the Earth's climate system, allowing scientists to predict the effects of greenhouse gas emissions on global temperatures. Similarly, computational models are used to study the behavior of fluids, the structure of materials, and the dynamics of galaxies. These models rely heavily on mathematical equations and algorithms, allowing scientists to explore complex phenomena and make predictions that would be impossible to obtain through traditional experimental methods.\\n\\nThe relationship between science and mathematics is not a one-way street. While science relies heavily on mathematics, mathematics also benefits from its interaction with science. Scientific problems often inspire new mathematical concepts and theories, pushing the boundaries of mathematical knowledge. For example, the development of calculus was motivated by the need to solve problems in physics, such as calculating the velocity and acceleration of moving objects. Similarly, the development of probability theory was motivated by the need to understand games of chance and to analyze statistical data.\\n\\nThe interplay between science and mathematics is a testament to the power of human curiosity and the pursuit of knowledge. By combining the empirical methods of science with the logical rigor of mathematics, we have been able to unlock the secrets of the universe and to develop technologies that have transformed our lives. From the development of antibiotics to the exploration of space, science and mathematics have worked together to advance our understanding of the world and to improve the human condition.\\n\\nThe importance of mathematics to science is not limited to specific disciplines or applications. It is a fundamental and pervasive aspect of the scientific process, shaping the way we think about the world and the way we conduct research. Without a strong foundation in mathematics, it is impossible to fully understand and appreciate the complexities of the natural world.\\n\\nIn conclusion, the relationship between science and mathematics is an essential and inseparable bond. Mathematics provides the language, the structure, and the logical framework that allows science to move beyond mere observation and into the realm of quantifiable understanding and predictive power. From formulating scientific theories to analyzing data and developing computational models, mathematics is an indispensable tool for scientific discovery. The interplay between science and mathematics is a testament to the power of human curiosity and the pursuit of knowledge, and it is essential for continuing to advance our understanding of the world and to improve the human condition. The future of science depends on a continued commitment to mathematical education and research, ensuring that we have the tools and the knowledge necessary to tackle the challenges that lie ahead. The ability to translate observations into mathematical models, to analyze data with statistical rigor, and to simulate complex systems with computational power is crucial for scientific progress. As we delve deeper into the mysteries of the universe, the importance of mathematics to science will only continue to grow, solidifying its role as the cornerstone of scientific understanding. The pursuit of knowledge, driven by curiosity and guided by the principles of science and mathematics, will undoubtedly lead to further breakthroughs and innovations that will shape the future of humanity. The ongoing dialogue between these two disciplines is a testament to the power of human intellect and the boundless potential for discovery that lies within the natural world.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--dba82194-3c19-468b-b4c1-d24fbb97aef2-0' usage_metadata={'input_tokens': 21, 'output_tokens': 1303, 'total_tokens': 1324, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"give me 1000 lines of essay on science and give the importance of it regarding mathematics?\")\n",
    "print(\"LLM Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6c658e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Okay, here's a joke about LangChain and ECS:\n",
      "\n",
      "Why did the LangChain agent refuse to deploy on ECS?\n",
      "\n",
      "Because it said, \"I'm designed to orchestrate complex language models, not container orchestration! I'm already dealing with enough chains, I don't need another one!\"\n",
      "Token Usage Stats: Tokens Used: 75\n",
      "\tPrompt Tokens: 9\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 66\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "with get_openai_callback() as cb:\n",
    "    response = llm.invoke(\"Tell me a joke about LangChain and ECS\")\n",
    "    print(\"Response:\", response.content)\n",
    "    print(\"Token Usage Stats:\", cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "950ac2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: What is Retrieval-Augmented Generation?\n",
      "A: Retrieval-Augmented Generation (RAG) is a technique that enhances the capabilities of large language models (LLMs) by allowing them to access and incorporate information from external knowledge sources during the generation process.  Think of it as giving an LLM a textbook or a library to consult before answering a question.\n",
      "\n",
      "Here's a breakdown of the key components and how it works:\n",
      "\n",
      "**1. The Problem RAG Solves:**\n",
      "\n",
      "* **LLMs have limited knowledge:** LLMs are trained on massive datasets, but their knowledge is frozen in time. They can't access real-time information or specific domain knowledge that wasn't included in their training data.\n",
      "* **Hallucinations:** LLMs can sometimes generate incorrect or nonsensical information, often referred to as \"hallucinations.\" This happens because they're trying to answer questions based on patterns learned during training, even if they don't have the actual facts.\n",
      "* **Lack of Transparency:** It's often difficult to understand why an LLM generated a particular response.  Without access to the source material, it's hard to verify the accuracy or relevance of the information.\n",
      "\n",
      "**2. How RAG Works:**\n",
      "\n",
      "RAG addresses these limitations by adding a retrieval step before the generation step.  Here's the typical process:\n",
      "\n",
      "* **a. User Query:** The user asks a question or provides a prompt.\n",
      "\n",
      "* **b. Retrieval:**\n",
      "    * **Indexing:**  The external knowledge source (e.g., a document database, a website, a knowledge graph) is indexed. This involves breaking down the information into smaller chunks (e.g., paragraphs, sentences) and creating vector embeddings for each chunk.  Vector embeddings are numerical representations that capture the semantic meaning of the text.\n",
      "    * **Similarity Search:** The user's query is also converted into a vector embedding.  Then, a similarity search is performed to find the chunks in the indexed knowledge source that are most semantically similar to the query.  This is often done using techniques like cosine similarity or dot product.\n",
      "\n",
      "* **c. Augmentation:** The retrieved chunks of information are combined with the original user query. This augmented prompt now contains both the user's question and relevant context from the external knowledge source.\n",
      "\n",
      "* **d. Generation:** The augmented prompt is fed into the LLM. The LLM uses this information to generate a more informed and accurate response.\n",
      "\n",
      "**3. Key Components in Detail:**\n",
      "\n",
      "* **Knowledge Source:** This is the external data source that the LLM will use to augment its knowledge. It can be:\n",
      "    * **Document Databases:** Collections of text documents (e.g., PDFs, Word documents, web pages).\n",
      "    * **Knowledge Graphs:** Structured representations of knowledge, with entities and relationships between them.\n",
      "    * **APIs:**  Allow access to real-time data from external services.\n",
      "    * **Databases:** Structured data stored in tables.\n",
      "\n",
      "* **Indexing:** The process of preparing the knowledge source for efficient retrieval.  This typically involves:\n",
      "    * **Chunking:** Dividing the data into smaller, manageable units.\n",
      "    * **Embedding:** Converting each chunk into a vector embedding using a pre-trained language model (e.g., Sentence Transformers, OpenAI Embeddings).\n",
      "\n",
      "* **Retrieval Model:**  The algorithm used to find the most relevant chunks of information based on the user's query.  Common techniques include:\n",
      "    * **Semantic Search:**  Finding chunks that are semantically similar to the query, even if they don't contain the exact same keywords.\n",
      "    * **Keyword Search:**  Finding chunks that contain specific keywords from the query.\n",
      "\n",
      "* **Large Language Model (LLM):** The model that generates the final response based on the augmented prompt.  Examples include:\n",
      "    * **GPT-3, GPT-4 (OpenAI)**\n",
      "    * **LaMDA (Google)**\n",
      "    * **LLaMA (Meta)**\n",
      "    * **Claude (Anthropic)**\n",
      "\n",
      "**4. Benefits of RAG:**\n",
      "\n",
      "* **Improved Accuracy:** By grounding the LLM's responses in external knowledge, RAG reduces the likelihood of hallucinations and improves the accuracy of the generated text.\n",
      "* **Up-to-Date Information:** RAG allows LLMs to access and incorporate real-time information, making them more useful for tasks that require current knowledge.\n",
      "* **Domain-Specific Knowledge:** RAG can be used to tailor LLMs to specific domains by providing them with access to relevant domain-specific knowledge sources.\n",
      "* **Transparency and Explainability:** RAG provides a way to trace the source of the information used to generate a response, making the process more transparent and explainable.  You can see which documents or data points the LLM used to form its answer.\n",
      "* **Reduced Training Costs:** Instead of retraining the entire LLM with new data, RAG allows you to update the knowledge source independently, which is more efficient and cost-effective.\n",
      "\n",
      "**5. Challenges of RAG:**\n",
      "\n",
      "* **Retrieval Quality:** The quality of the retrieved information is crucial. If the retrieval model fails to find relevant information, the LLM will still generate a poor response.\n",
      "* **Chunking Strategy:**  Choosing the right chunk size is important.  Too small, and the context is lost.  Too large, and the retrieval becomes less precise.\n",
      "* **Computational Cost:**  Indexing and retrieving information can be computationally expensive, especially for large knowledge sources.\n",
      "* **Noise in Retrieved Context:**  The retrieved context might contain irrelevant or noisy information, which can negatively impact the LLM's performance.\n",
      "* **Prompt Engineering:**  Crafting effective prompts that guide the LLM to use the retrieved information effectively is important.\n",
      "\n",
      "**6. Use Cases:**\n",
      "\n",
      "* **Question Answering:** Answering questions based on a specific document or knowledge base.\n",
      "* **Chatbots:** Building chatbots that can provide accurate and informative responses to user queries.\n",
      "* **Content Generation:** Generating articles, reports, or other types of content based on external data sources.\n",
      "* **Code Generation:** Generating code snippets based on documentation or API specifications.\n",
      "* **Summarization:** Summarizing long documents or articles.\n",
      "\n",
      "**In summary, Retrieval-Augmented Generation is a powerful technique that combines the strengths of retrieval-based and generation-based approaches to create more accurate, informative, and transparent LLM applications.** It's a rapidly evolving field with ongoing research focused on improving the efficiency and effectiveness of the retrieval and generation processes.\n",
      "\n",
      "Q: How does FAISS indexing work?\n",
      "A: FAISS (Facebook AI Similarity Search) is a library designed for efficient similarity search and clustering of dense vectors. It's particularly useful for large datasets where brute-force search becomes computationally expensive. Here's a breakdown of how FAISS indexing works, covering the key concepts and techniques:\n",
      "\n",
      "**1. The Problem: Nearest Neighbor Search**\n",
      "\n",
      "The core problem FAISS addresses is finding the *k* nearest neighbors (k-NN) to a query vector within a large dataset of vectors.  A naive approach would involve calculating the distance between the query vector and every vector in the dataset, which is O(N) complexity (where N is the number of vectors).  For millions or billions of vectors, this is impractical.\n",
      "\n",
      "**2. FAISS's Approach: Approximate Nearest Neighbor (ANN) Search**\n",
      "\n",
      "FAISS uses various techniques to perform *approximate* nearest neighbor search.  This means it might not always find the absolute closest neighbors, but it finds neighbors that are very close with high probability, and it does so much faster than brute-force.  The trade-off is accuracy for speed.\n",
      "\n",
      "**3. Key Concepts and Techniques**\n",
      "\n",
      "*   **Vector Quantization:** This is a fundamental technique used in many FAISS indexes.  It involves dividing the vector space into a set of discrete regions (cells or clusters) represented by *centroids*.  Instead of comparing the query vector to every vector in the dataset, you first find the closest centroid and then only compare the query vector to the vectors within that centroid's region.  This significantly reduces the search space.\n",
      "\n",
      "*   **Index Types:** FAISS offers a wide variety of index types, each optimized for different scenarios (dataset size, vector dimensionality, accuracy requirements, memory constraints, etc.).  Here are some common ones:\n",
      "\n",
      "    *   **Flat Index:** This is the simplest index. It stores the vectors directly and performs a brute-force search.  It's accurate but slow for large datasets.  Useful as a baseline.\n",
      "\n",
      "    *   **IVF (Inverted File):**  This is a popular and versatile index.  It combines vector quantization with an inverted index.\n",
      "        *   **Training:**  A set of vectors is used to train a quantizer (e.g., k-means).  The quantizer learns the centroids of the clusters.\n",
      "        *   **Indexing:** Each vector in the dataset is assigned to the closest centroid (cluster).  An inverted index is created, mapping each centroid to the list of vectors belonging to that cluster.\n",
      "        *   **Searching:**  The query vector is compared to a small number of centroids (controlled by the `nprobe` parameter).  The vectors within the corresponding clusters are then searched exhaustively.  Increasing `nprobe` increases accuracy but also increases search time.\n",
      "\n",
      "    *   **PQ (Product Quantization):**  This technique divides the vector into subvectors and quantizes each subvector independently.  This allows for a more compact representation of the vectors, reducing memory usage.  It's often used in combination with IVF (IVF-PQ).\n",
      "\n",
      "    *   **HNSW (Hierarchical Navigable Small World):**  This is a graph-based index that builds a multi-layered graph structure.  Each layer represents the data at a different level of granularity.  Searching involves traversing the graph from the top layer to the bottom, progressively refining the search.  HNSW is known for its good accuracy and speed, especially for high-dimensional data.\n",
      "\n",
      "    *   **OPQ (Optimized Product Quantization):**  An extension of PQ that learns a rotation matrix to pre-process the vectors before applying PQ. This can improve the accuracy of the quantization.\n",
      "\n",
      "*   **Distance Metrics:** FAISS supports various distance metrics, including:\n",
      "\n",
      "    *   **L2 (Euclidean) distance:** The most common distance metric.\n",
      "    *   **Inner Product (Dot Product):**  Useful for cosine similarity.\n",
      "    *   **L1 (Manhattan) distance:** Less common but can be useful in some cases.\n",
      "\n",
      "*   **Training:** Many FAISS indexes require a training step.  This involves providing a representative subset of the data to the index so it can learn the data distribution and optimize its internal parameters (e.g., cluster centroids for IVF).\n",
      "\n",
      "*   **Parameters:**  FAISS indexes have various parameters that control their behavior, such as:\n",
      "\n",
      "    *   `nlist`: The number of clusters in an IVF index.\n",
      "    *   `nprobe`: The number of clusters to search during a query in an IVF index.\n",
      "    *   `M`: The number of subvectors in a PQ index.\n",
      "    *   `efConstruction`:  A parameter in HNSW that controls the quality of the graph during construction.\n",
      "    *   `efSearch`: A parameter in HNSW that controls the search effort.\n",
      "\n",
      "**4. Workflow**\n",
      "\n",
      "1.  **Data Preparation:**  Convert your data into a matrix of dense vectors (e.g., NumPy array).  Ensure the data type is appropriate (e.g., `float32`).\n",
      "\n",
      "2.  **Index Selection:** Choose the appropriate index type based on your data size, dimensionality, accuracy requirements, and memory constraints.  Experimentation is often necessary to find the best index for your specific use case.\n",
      "\n",
      "3.  **Training (if required):**  Train the index using a representative subset of your data.\n",
      "\n",
      "4.  **Indexing:** Add the vectors to the index.\n",
      "\n",
      "5.  **Searching:**  Perform similarity searches using query vectors.  Adjust the index parameters (e.g., `nprobe` for IVF, `efSearch` for HNSW) to balance accuracy and speed.\n",
      "\n",
      "**5. Example (Simplified IVF)**\n",
      "\n",
      "Let's illustrate the IVF index with a simplified example:\n",
      "\n",
      "1.  **Training:**\n",
      "    *   You have 1000 vectors.\n",
      "    *   You choose `nlist = 10` (10 clusters).\n",
      "    *   You train a k-means algorithm on a subset of the 1000 vectors to find 10 cluster centroids.\n",
      "\n",
      "2.  **Indexing:**\n",
      "    *   For each of the 1000 vectors, you find the closest centroid.\n",
      "    *   You create an inverted index:\n",
      "        *   Centroid 1: [vector_id_1, vector_id_5, vector_id_12, ...]\n",
      "        *   Centroid 2: [vector_id_2, vector_id_8, vector_id_20, ...]\n",
      "        *   ...\n",
      "        *   Centroid 10: [vector_id_3, vector_id_9, vector_id_15, ...]\n",
      "\n",
      "3.  **Searching:**\n",
      "    *   You have a query vector.\n",
      "    *   You choose `nprobe = 2` (search 2 clusters).\n",
      "    *   You find the 2 closest centroids to the query vector (e.g., Centroids 3 and 7).\n",
      "    *   You retrieve the vectors associated with Centroids 3 and 7 from the inverted index.\n",
      "    *   You calculate the distances between the query vector and all the vectors in those two clusters.\n",
      "    *   You return the `k` nearest neighbors from those vectors.\n",
      "\n",
      "**6. Advantages of FAISS**\n",
      "\n",
      "*   **Speed:**  Significantly faster than brute-force search for large datasets.\n",
      "*   **Scalability:**  Handles millions or billions of vectors.\n",
      "*   **Memory Efficiency:**  Offers techniques like PQ to reduce memory usage.\n",
      "*   **Flexibility:**  Provides a wide range of index types and distance metrics.\n",
      "*   **GPU Support:**  Can leverage GPUs for even faster search.\n",
      "*   **Open Source:**  Freely available and actively maintained.\n",
      "\n",
      "**7. Considerations**\n",
      "\n",
      "*   **Accuracy vs. Speed Trade-off:**  ANN search is approximate, so you need to balance accuracy and speed by tuning the index parameters.\n",
      "*   **Index Selection:**  Choosing the right index type is crucial for performance.  Experimentation is often required.\n",
      "*   **Training Data:**  The quality of the training data can affect the accuracy of the index.\n",
      "*   **Parameter Tuning:**  Optimizing the index parameters can significantly improve performance.\n",
      "\n",
      "In summary, FAISS provides a powerful set of tools for efficient similarity search in large datasets. By using techniques like vector quantization and inverted indexes, it significantly reduces the search space, enabling fast and scalable nearest neighbor search. Understanding the different index types and their parameters is key to effectively using FAISS for your specific application.\n",
      "\n",
      "Q: What is the difference between fine-tuning and RAG?\n",
      "A: Both fine-tuning and Retrieval-Augmented Generation (RAG) are techniques used to improve the performance of Large Language Models (LLMs) on specific tasks or with specific knowledge. However, they achieve this in fundamentally different ways:\n",
      "\n",
      "**Fine-tuning:**\n",
      "\n",
      "*   **Mechanism:** Modifies the internal parameters (weights) of the LLM itself. It's like teaching the LLM new skills or refining its existing ones by showing it a lot of examples.\n",
      "*   **Process:** Requires a dataset of labeled examples relevant to the target task. The LLM is trained on this dataset, adjusting its internal parameters to better predict the correct outputs.\n",
      "*   **Knowledge Integration:** Directly embeds new knowledge into the LLM's parameters. The model *learns* the information and can recall it directly from its memory.\n",
      "*   **Advantages:**\n",
      "    *   Can lead to better performance on tasks that require complex reasoning or understanding of nuanced patterns in the training data.\n",
      "    *   Faster inference speed once fine-tuning is complete, as the knowledge is already integrated into the model.\n",
      "    *   Can improve the model's ability to follow specific instructions or adopt a particular style.\n",
      "*   **Disadvantages:**\n",
      "    *   Requires a significant amount of labeled data, which can be expensive and time-consuming to create.\n",
      "    *   Can be computationally expensive and time-consuming to train.\n",
      "    *   Risk of overfitting to the training data, leading to poor generalization on unseen data.\n",
      "    *   \"Catastrophic forgetting\": The model might forget previously learned information during fine-tuning.\n",
      "    *   Difficult to update the model with new information after fine-tuning without retraining.\n",
      "    *   Can be harder to interpret and control the model's behavior after fine-tuning.\n",
      "\n",
      "**Retrieval-Augmented Generation (RAG):**\n",
      "\n",
      "*   **Mechanism:** Augments the LLM's input with relevant information retrieved from an external knowledge source (e.g., a database, a collection of documents, or the internet).\n",
      "*   **Process:**\n",
      "    1.  The user's query is used to retrieve relevant information from the external knowledge source.\n",
      "    2.  The retrieved information is combined with the original query and fed into the LLM.\n",
      "    3.  The LLM generates a response based on both the query and the retrieved information.\n",
      "*   **Knowledge Integration:** Doesn't directly embed knowledge into the LLM. Instead, it provides the LLM with the necessary information at the time of inference.\n",
      "*   **Advantages:**\n",
      "    *   Doesn't require retraining the LLM, making it more efficient and cost-effective.\n",
      "    *   Allows the LLM to access and utilize a vast amount of information that it wasn't trained on.\n",
      "    *   Easier to update the knowledge source with new information without affecting the LLM.\n",
      "    *   More transparent and controllable, as the retrieved information provides context for the LLM's response.\n",
      "    *   Reduces the risk of hallucination (generating incorrect or nonsensical information) by grounding the LLM in factual knowledge.\n",
      "*   **Disadvantages:**\n",
      "    *   Performance depends on the quality of the retrieval mechanism and the knowledge source.\n",
      "    *   Can be slower than fine-tuning, as it requires retrieving information before generating a response.\n",
      "    *   The LLM may struggle to integrate the retrieved information effectively, especially if it's poorly formatted or irrelevant.\n",
      "    *   Requires managing and maintaining the external knowledge source.\n",
      "\n",
      "**Here's an analogy:**\n",
      "\n",
      "*   **Fine-tuning:**  Imagine teaching a student a new subject by having them study a textbook and do practice problems. The student internalizes the knowledge and can answer questions directly from memory.\n",
      "*   **RAG:** Imagine giving a student access to a library while they're taking a test. They can look up information in the library to help them answer the questions.\n",
      "\n",
      "**In summary:**\n",
      "\n",
      "| Feature          | Fine-tuning                               | RAG                                         |\n",
      "|-------------------|-------------------------------------------|---------------------------------------------|\n",
      "| **Mechanism**    | Modifies LLM parameters                  | Augments LLM input with retrieved data     |\n",
      "| **Knowledge**    | Embedded in LLM                          | External knowledge source                   |\n",
      "| **Training**     | Requires training data and retraining     | No retraining required                      |\n",
      "| **Update**       | Difficult to update                       | Easy to update                               |\n",
      "| **Speed**        | Faster inference                          | Slower inference (due to retrieval)         |\n",
      "| **Data Needs**   | Large, labeled dataset                    | External knowledge source (can be unlabeled) |\n",
      "| **Hallucination**| Higher risk                               | Lower risk                                  |\n",
      "\n",
      "**When to use which?**\n",
      "\n",
      "*   **Fine-tuning:** Use when you need to improve the LLM's performance on a specific task that requires complex reasoning or understanding of nuanced patterns, and you have a good amount of labeled data.  Also useful when you need the fastest possible inference speed.\n",
      "*   **RAG:** Use when you need to provide the LLM with access to a large and constantly evolving knowledge base, and you want to avoid retraining the LLM.  Also useful when you want to reduce the risk of hallucination and provide more transparent and controllable responses.\n",
      "\n",
      "In some cases, a combination of both fine-tuning and RAG can be used to achieve optimal performance. For example, you might fine-tune an LLM to be better at using a specific retrieval system, and then use RAG to provide it with the necessary information at inference time.\n",
      "\n",
      "=== Token Usage Summary ===\n",
      "Total Tokens: 4357\n",
      "Prompt Tokens: 26\n",
      "Completion Tokens: 4331\n",
      "Total Cost (USD): $0.000000\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"What is Retrieval-Augmented Generation?\",\n",
    "    \"How does FAISS indexing work?\",\n",
    "    \"What is the difference between fine-tuning and RAG?\"\n",
    "]\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    for q in questions:\n",
    "        answer = llm.invoke(q)\n",
    "        print(f\"\\nQ: {q}\\nA: {answer.content}\")\n",
    "\n",
    "    print(\"\\n=== Token Usage Summary ===\")\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97405c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
